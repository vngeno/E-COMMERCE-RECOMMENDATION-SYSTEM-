{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchCollaborative.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vngeno/E-COMMERCE-RECOMMENDATION-SYSTEM-/blob/Collaborative-Based-Filtering/PytorchCollaborative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFOt8cvm3-GA"
      },
      "source": [
        "\n",
        "# Collaborative Filterting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTwNlbZQ4Bzm"
      },
      "source": [
        "#Import libraries required\n",
        "import math\n",
        "import copy\n",
        "import zipfile\n",
        "from textwrap import wrap\n",
        "from pathlib import Path\n",
        "from itertools import zip_longest\n",
        "from collections import defaultdict\n",
        "from urllib.error import URLError\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F \n",
        "from torch.optim.lr_scheduler import _LRScheduler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR9UAwfg4LJt"
      },
      "source": [
        "#State the random state\n",
        "def set_random_seed(state=1):\n",
        "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
        "    for set_state in gens:\n",
        "        set_state(state)\n",
        "\n",
        "RANDOM_STATE = 1\n",
        "set_random_seed(RANDOM_STATE)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0NOzTFu8o_M"
      },
      "source": [
        "Dataset Preview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5IOzasPMsHx",
        "outputId": "e60e53a9-0b32-4abb-ebe9-370952cf4d8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjOGKuomM0k4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303cac0e-a23f-442d-8ac8-27141fc52bc3"
      },
      "source": [
        "#Load the dataset and preview the columns\n",
        "df = pd.read_csv('/content/drive/Shareddrives/Team Stars/Data/df_clean.csv',index_col=0)\n",
        "df.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'brand', 'primarycategories', 'manufacturernumber',\n",
              "       'reviews_dorecommend', 'reviews_numhelpful', 'reviews_rating',\n",
              "       'reviews_text', 'reviews_title', 'reviews_username'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yGtNLFiN90k"
      },
      "source": [
        "#label encode the id and username to get the userid and productid\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df.id=le.fit_transform(df.id)\n",
        "df.reviews_username=le.fit_transform(df.reviews_username)\n",
        "df.reviews_rating=le.fit_transform(df.reviews_rating)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJeKkUn9P4Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a24a3be-cc0b-44fb-f0be-a08ce5dab9b4"
      },
      "source": [
        "#Rename the columns\n",
        "df=df.rename(columns={'id':'productId','reviews_username':'userId','reviews_rating':'rating','brand':'brand','name':'title'})\n",
        "df.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['productId', 'title', 'brand', 'primarycategories',\n",
              "       'manufacturernumber', 'reviews_dorecommend', 'reviews_numhelpful',\n",
              "       'rating', 'reviews_text', 'reviews_title', 'userId'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfN5p5zgNRyP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "3ba519f0-bf59-4b3b-b0b3-60d1085f2b9a"
      },
      "source": [
        "#Define the ratimg dataset\n",
        "ratings=df[['userId','productId','rating']]\n",
        "ratings.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>productId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8417</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5201</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6994</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8769</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8713</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  productId  rating\n",
              "0    8417         21       2\n",
              "1    5201         21       3\n",
              "2    6994         21       4\n",
              "3    8769         21       4\n",
              "4    8713         21       4"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEFMQEmtO9Zv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "98893a61-0b45-4ef6-e7a1-7b27d042273f"
      },
      "source": [
        "#Define the product dataset\n",
        "products=df[['productId','title','brand']]\n",
        "products.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>productId</th>\n",
              "      <th>title</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Amazonbasics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Amazonbasics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Amazonbasics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Amazonbasics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Amazonbasics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   productId                                              title         brand\n",
              "0         21  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics\n",
              "1         21  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics\n",
              "2         21  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics\n",
              "3         21  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics\n",
              "4         21  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtV55r168tgO"
      },
      "source": [
        "#Creating a cross-tabular view of users vs product\n",
        "def tabular_preview(ratings, n=15):\n",
        "    #Group by users\n",
        "    user_groups = ratings.groupby('userId')['rating'].count()\n",
        "    top_users = user_groups.sort_values(ascending=False)[:15]\n",
        "\n",
        "    #group by products\n",
        "    product_groups = ratings.groupby('productId')['rating'].count()\n",
        "    top_products = product_groups.sort_values(ascending=False)[:15]\n",
        "\n",
        "    top = (\n",
        "        ratings.\n",
        "        join(top_users, rsuffix='_r', how='inner', on='userId').\n",
        "        join(top_products, rsuffix='_r', how='inner', on='productId'))\n",
        "\n",
        "    return pd.crosstab(top.userId, top.productId, top.rating, aggfunc=np.sum)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-db28k58x70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "b0bcdf85-cac9-485e-f9e9-8f82808ffb16"
      },
      "source": [
        "#Preview the crosstab\n",
        "tabular_preview(ratings, products)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>productId</th>\n",
              "      <th>7</th>\n",
              "      <th>15</th>\n",
              "      <th>18</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>25</th>\n",
              "      <th>27</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>44</th>\n",
              "      <th>48</th>\n",
              "      <th>51</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1151</th>\n",
              "      <td>942.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2037.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4730</th>\n",
              "      <td>36.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>121.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5588</th>\n",
              "      <td>35.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9496</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9779</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11047</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11544</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11948</th>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12232</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12323</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12923</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "productId     7     15    18      21    22  ...    39    40    44   48    51\n",
              "userId                                      ...                             \n",
              "219          NaN   NaN   3.0     NaN  14.0  ...   NaN   8.0  11.0  NaN   4.0\n",
              "323          NaN   4.0   4.0     NaN  13.0  ...   NaN  13.0   7.0  NaN   NaN\n",
              "701          NaN   NaN  10.0     NaN   8.0  ...   NaN   8.0   9.0  NaN   NaN\n",
              "739          NaN   NaN   6.0     NaN  14.0  ...   NaN   3.0   6.0  NaN   6.0\n",
              "1151       942.0   NaN   NaN  2037.0   NaN  ...   NaN   NaN   NaN  NaN   NaN\n",
              "4730        36.0   NaN   NaN   121.0   NaN  ...   NaN   NaN   NaN  NaN   NaN\n",
              "5588        35.0   NaN   NaN    53.0   NaN  ...   NaN   NaN   NaN  NaN   NaN\n",
              "9496         NaN   NaN  22.0     NaN   4.0  ...  10.0   NaN  18.0  4.0  10.0\n",
              "9779         NaN   4.0  19.0     NaN   8.0  ...   NaN   8.0  24.0  4.0   4.0\n",
              "11047        NaN   4.0   NaN     NaN   7.0  ...   4.0   7.0  19.0  8.0   NaN\n",
              "11544        NaN   4.0   4.0     NaN   6.0  ...   NaN   6.0  17.0  NaN   4.0\n",
              "11948        NaN  17.0  20.0     NaN  11.0  ...   4.0  11.0  36.0  3.0  16.0\n",
              "12232        NaN   NaN  25.0     NaN   8.0  ...   NaN   4.0  11.0  NaN   4.0\n",
              "12323        NaN   2.0   4.0     NaN   7.0  ...   NaN   4.0  16.0  3.0   8.0\n",
              "12923        NaN   NaN   NaN     NaN  16.0  ...   4.0  12.0  12.0  NaN   4.0\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKANn_9s85sC"
      },
      "source": [
        "**Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMguijI19AYa"
      },
      "source": [
        "#Create a dataset\n",
        "def create_dataset(ratings, top=None):\n",
        "    if top is not None:\n",
        "        ratings.groupby('userId')['rating'].count()\n",
        "    \n",
        "    #get the unique users\n",
        "    unique_users = ratings.userId.unique()\n",
        "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
        "    new_users = ratings.userId.map(user_to_index)\n",
        "    \n",
        "    #Get the unique products\n",
        "    unique_products = ratings.productId.unique()\n",
        "    product_to_index = {old: new for new, old in enumerate(unique_products)}\n",
        "    new_products = ratings.productId.map(product_to_index)\n",
        "    \n",
        "    n_users = unique_users.shape[0]\n",
        "    n_products = unique_products.shape[0]\n",
        "    \n",
        "    X = pd.DataFrame({'user_id': new_users, 'product_id': new_products})\n",
        "    y = ratings['rating'].astype(np.float32)\n",
        "    return (n_users, n_products), (X, y), (user_to_index, product_to_index)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjxev-rh9Ayj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fc20cc-d6af-42c5-b35b-e1bd36701119"
      },
      "source": [
        "#Create the embeddings between users and products\n",
        "(n, m), (X, y), _ = create_dataset(ratings)\n",
        "print(f'Embeddings: {n} users, {m} products')\n",
        "print(f'Dataset shape: {X.shape}')\n",
        "print(f'Target shape: {y.shape}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings: 16269 users, 65 products\n",
            "Dataset shape: (28332, 2)\n",
            "Target shape: (28332,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oySRKg_n9FWH"
      },
      "source": [
        "#Iterate among the reviews\n",
        "class ReviewsIterator:\n",
        "    \n",
        "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
        "        X, y = np.asarray(X), np.asarray(y)\n",
        "        \n",
        "        if shuffle:\n",
        "            index = np.random.permutation(X.shape[0])\n",
        "            X, y = X[index], y[index]\n",
        "            \n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
        "        self._current = 0\n",
        "        \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        return self.next()\n",
        "    \n",
        "    def next(self):\n",
        "        if self._current >= self.n_batches:\n",
        "            raise StopIteration()\n",
        "        k = self._current\n",
        "        self._current += 1\n",
        "        bs = self.batch_size\n",
        "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsPQnt_x9IYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f55908c-e8c7-42f6-df1c-4386911ff3be"
      },
      "source": [
        "def batches(X, y, bs=32, shuffle=True):\n",
        "    for xb, yb in ReviewsIterator(X, y, bs, shuffle):\n",
        "        xb = torch.LongTensor(xb)\n",
        "        yb = torch.FloatTensor(yb)\n",
        "        yield xb, yb.view(-1, 1)\n",
        "\n",
        "for x_batch, y_batch in batches(X, y, bs=4):\n",
        "    print(x_batch)\n",
        "    print(y_batch)\n",
        "    break"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 8261,     6],\n",
            "        [12801,    57],\n",
            "        [ 9118,    19],\n",
            "        [ 3887,     0]])\n",
            "tensor([[4.],\n",
            "        [4.],\n",
            "        [4.],\n",
            "        [3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ddhoFWT9Pbl"
      },
      "source": [
        "**Embeddings**\n",
        "\n",
        "As it is a natural language dataset, embedding has to be done. We haved done it with neural based embedding.\n",
        "Creates a dense network with embedding layers. \n",
        "    Args:\n",
        "    \n",
        "        n_users:            \n",
        "            Number of unique users in the dataset.\n",
        "\n",
        "        n_products: \n",
        "            Number of unique products in the dataset.\n",
        "\n",
        "        n_factors: \n",
        "            Number of columns in the embeddings matrix.\n",
        "\n",
        "        embedding_dropout: \n",
        "            Dropout rate to apply right after embeddings layer.\n",
        "\n",
        "        hidden:\n",
        "            A single integer or a list of integers defining the number of \n",
        "            units in hidden layer(s).\n",
        "\n",
        "        dropouts: \n",
        "            A single integer or a list of integers defining the dropout \n",
        "            layers rates applyied right after each of hidden layers.\n",
        "            \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpak-EEm9M-J"
      },
      "source": [
        "class EmbeddingNet(nn.Module):\n",
        "   \n",
        "    def __init__(self, n_users, n_products,\n",
        "                 n_factors=50, embedding_dropout=0.02, \n",
        "                 hidden=10, dropouts=0.2):\n",
        "        super().__init__()\n",
        "        hidden = get_list(hidden)\n",
        "        dropouts = get_list(dropouts)\n",
        "        n_last = hidden[-1]\n",
        "        \n",
        "        def gen_layers(n_in):\n",
        "            \"\"\"\n",
        "            A generator that yields a sequence of hidden layers and \n",
        "            their activations/dropouts.\n",
        "            \n",
        "            Note that the function captures `hidden` and `dropouts` \n",
        "            values from the outer scope.\n",
        "            \"\"\"\n",
        "            nonlocal hidden, dropouts\n",
        "            assert len(dropouts) <= len(hidden)\n",
        "            \n",
        "            for n_out, rate in zip_longest(hidden, dropouts):\n",
        "                yield nn.Linear(n_in, n_out)\n",
        "                yield nn.ReLU()\n",
        "                if rate is not None and rate > 0.:\n",
        "                    yield nn.Dropout(rate)\n",
        "                n_in = n_out\n",
        "            \n",
        "        self.u = nn.Embedding(n_users, n_factors)\n",
        "        self.m = nn.Embedding(n_products, n_factors)\n",
        "        self.drop = nn.Dropout(embedding_dropout)\n",
        "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
        "        self.fc = nn.Linear(n_last, 1)\n",
        "        self._init()\n",
        "        \n",
        "    def forward(self, users, products, minmax=None):\n",
        "        features = torch.cat([self.u(users), self.m(products)], dim=1)\n",
        "        x = self.drop(features)\n",
        "        x = self.hidden(x)\n",
        "        out = torch.sigmoid(self.fc(x))\n",
        "        if minmax is not None:\n",
        "            min_rating, max_rating = minmax\n",
        "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
        "        return out\n",
        "    \n",
        "    def _init(self):\n",
        "        \"\"\"\n",
        "        Setup embeddings and hidden layers with reasonable initial values.\n",
        "        \"\"\"\n",
        "        \n",
        "        def init(m):\n",
        "            if type(m) == nn.Linear:\n",
        "                torch.nn.init.xavier_uniform_(m.weight)\n",
        "                m.bias.data.fill_(0.01)\n",
        "                \n",
        "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
        "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
        "        self.hidden.apply(init)\n",
        "        init(self.fc)\n",
        "    \n",
        "    \n",
        "def get_list(n):\n",
        "    if isinstance(n, (int, float)):\n",
        "        return [n]\n",
        "    elif hasattr(n, '__iter__'):\n",
        "        return list(n)\n",
        "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ6aOOTq96cD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369a215f-c769-49be-8197-9d74246fc9c2"
      },
      "source": [
        "#Call the class\n",
        "EmbeddingNet(n, m, n_factors=150, hidden=100, dropouts=0.5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmbeddingNet(\n",
              "  (u): Embedding(16269, 150)\n",
              "  (m): Embedding(65, 150)\n",
              "  (drop): Dropout(p=0.02, inplace=False)\n",
              "  (hidden): Sequential(\n",
              "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGpq9aWz98CQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837ab602-1998-4d0e-f9c2-c13cf9935934"
      },
      "source": [
        "#Optimize to the hidden layers\n",
        "EmbeddingNet(n, m, n_factors=150, hidden=[100, 200, 300], dropouts=[0.25, 0.5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmbeddingNet(\n",
              "  (u): Embedding(16269, 150)\n",
              "  (m): Embedding(65, 150)\n",
              "  (drop): Dropout(p=0.02, inplace=False)\n",
              "  (hidden): Sequential(\n",
              "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.25, inplace=False)\n",
              "    (3): Linear(in_features=100, out_features=200, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=200, out_features=300, bias=True)\n",
              "    (7): ReLU()\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8y9hcuO-AlY"
      },
      "source": [
        "**Cyclical Learning Rate (CLR)**\n",
        "\n",
        "One of the fastai library features is the cyclical learning rate scheduler. We can implement something similar inheriting the _LRScheduler class from the torch library. Following the original paper's pseudocode, this CLR Keras callback implementation, and making a couple of adjustments to support cosine annealing with restarts, let's create our own CLR scheduler.\n",
        "\n",
        "The implementation of this idea is quite simple. The base PyTorch scheduler class has the get_lr() method that is invoked each time when we call the step() method. The method should return a list of learning rates depending on the current training epoch. In our case, we have the same learning rate for all of the layers, and therefore, we return a list with a single value.\n",
        "\n",
        "We define a CyclicLR class that expectes a single callback function. This function should accept the current training epoch and the base value of learning rate, and return a new learning rate value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbSnnMp099l7"
      },
      "source": [
        "#Define the class\n",
        "class CyclicLR(_LRScheduler):\n",
        "    \n",
        "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
        "        assert callable(schedule)\n",
        "        self.schedule = schedule\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R_8iqrK-Jhp"
      },
      "source": [
        "def triangular(step_size, max_lr, method='triangular', gamma=0.99):\n",
        "    \n",
        "    def scheduler(epoch, base_lr):\n",
        "        period = 2 * step_size\n",
        "        cycle = math.floor(1 + epoch/period)\n",
        "        x = abs(epoch/step_size - 2*cycle + 1)\n",
        "        delta = (max_lr - base_lr)*max(0, (1 - x))\n",
        "\n",
        "        if method == 'triangular':\n",
        "            pass  # we've already done\n",
        "        elif method == 'triangular2':\n",
        "            delta /= float(2 ** (cycle - 1))\n",
        "        elif method == 'exp_range':\n",
        "            delta *= (gamma**epoch)\n",
        "        else:\n",
        "            raise ValueError('unexpected method: %s' % method)\n",
        "            \n",
        "        return base_lr + delta\n",
        "        \n",
        "    return scheduler"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smzCPCHd-LVx"
      },
      "source": [
        "def cosine(t_max, eta_min=0):\n",
        "    \n",
        "    def scheduler(epoch, base_lr):\n",
        "        t = epoch % t_max\n",
        "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
        "    \n",
        "    return scheduler"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipaJMGst-N_2"
      },
      "source": [
        "def plot_lr(schedule):\n",
        "    ts = list(range(1000))\n",
        "    y = [schedule(t, 0.001) for t in ts]\n",
        "    plt.plot(ts, y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heZr-5if-VRF"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEJg2qwu-P77"
      },
      "source": [
        "#Split, train and test\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid)}\n",
        "dataset_sizes = {'train': len(X_train), 'val': len(X_valid)}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o69_urDR-hH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038e5299-5375-43ce-86d6-cc866ddba71c"
      },
      "source": [
        "#Define an array with the minimum and maximum ratings\n",
        "minmax = float(ratings.rating.min()), float(ratings.rating.max())\n",
        "minmax"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 4.0)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt18Wq3F-jCw"
      },
      "source": [
        "#Call the class and pass the parameters\n",
        "net = EmbeddingNet(\n",
        "    n_users=n, n_products=m, \n",
        "    n_factors=150, hidden=[500, 500, 500], \n",
        "    embedding_dropout=0.05, dropouts=[0.5, 0.5, 0.25])\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARx3Wr0r_XeT"
      },
      "source": [
        "#Training loop parameters\n",
        "lr = 1e-3\n",
        "wd = 1e-5 \n",
        "bs = 2000\n",
        "n_epochs = 100\n",
        "patience = 10\n",
        "no_improvements = 0\n",
        "best_loss = np.inf\n",
        "best_weights = None\n",
        "history = []\n",
        "lr_history = []\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net.to(device)\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
        "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
        "scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CBc3GV0-sLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e266a8-7079-43e8-8fe4-424c8a57d1e1"
      },
      "source": [
        "#Start training the loops\n",
        "for epoch in range(n_epochs):\n",
        "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
        "    \n",
        "    for phase in ('train', 'val'):\n",
        "        if phase == 'train':\n",
        "          training = True\n",
        "        else:\n",
        "          training = False\n",
        "\n",
        "        running_loss = 0\n",
        "        n_batches = 0\n",
        "        \n",
        "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
        "            x_batch, y_batch = [b.to(device) for b in batch]\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #print(x_batch[:,0])\n",
        "          \n",
        "        \n",
        "            # compute gradients only during 'train' phase\n",
        "            with torch.set_grad_enabled(training):\n",
        "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                \n",
        "                # don't update weights and rates when in 'val' phase\n",
        "                if training:\n",
        "                    scheduler.step()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    lr_history.extend(scheduler.get_lr())\n",
        "                    \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        stats[phase] = epoch_loss\n",
        "        \n",
        "        # early stopping: save weights of the best model so far\n",
        "        if phase == 'val':\n",
        "            if epoch_loss < best_loss:\n",
        "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
        "                best_loss = epoch_loss\n",
        "                best_weights = copy.deepcopy(net.state_dict())\n",
        "                no_improvements = 0\n",
        "            else:\n",
        "                no_improvements += 1\n",
        "                \n",
        "    history.append(stats)\n",
        "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
        "    if no_improvements >= patience:\n",
        "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
        "        break"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss improvement on epoch: 1\n",
            "[001/100] train: 1.3957 - val: 0.6949\n",
            "loss improvement on epoch: 2\n",
            "[002/100] train: 0.8824 - val: 0.6026\n",
            "loss improvement on epoch: 3\n",
            "[003/100] train: 0.8485 - val: 0.5745\n",
            "loss improvement on epoch: 4\n",
            "[004/100] train: 0.7619 - val: 0.5585\n",
            "loss improvement on epoch: 5\n",
            "[005/100] train: 0.6365 - val: 0.5072\n",
            "loss improvement on epoch: 6\n",
            "[006/100] train: 0.4851 - val: 0.5011\n",
            "[007/100] train: 0.3959 - val: 0.5264\n",
            "[008/100] train: 0.3469 - val: 0.5353\n",
            "[009/100] train: 0.3094 - val: 0.5256\n",
            "[010/100] train: 0.2909 - val: 0.5426\n",
            "[011/100] train: 0.2647 - val: 0.5577\n",
            "[012/100] train: 0.2388 - val: 0.5603\n",
            "[013/100] train: 0.2144 - val: 0.5306\n",
            "[014/100] train: 0.2001 - val: 0.5121\n",
            "loss improvement on epoch: 15\n",
            "[015/100] train: 0.1807 - val: 0.4927\n",
            "[016/100] train: 0.1669 - val: 0.4960\n",
            "loss improvement on epoch: 17\n",
            "[017/100] train: 0.1634 - val: 0.4895\n",
            "loss improvement on epoch: 18\n",
            "[018/100] train: 0.1605 - val: 0.4874\n",
            "[019/100] train: 0.1553 - val: 0.4943\n",
            "[020/100] train: 0.1525 - val: 0.4950\n",
            "[021/100] train: 0.1513 - val: 0.4961\n",
            "[022/100] train: 0.1478 - val: 0.5011\n",
            "[023/100] train: 0.1489 - val: 0.5019\n",
            "[024/100] train: 0.1442 - val: 0.5038\n",
            "[025/100] train: 0.1438 - val: 0.5072\n",
            "[026/100] train: 0.1397 - val: 0.5008\n",
            "[027/100] train: 0.1414 - val: 0.5073\n",
            "[028/100] train: 0.1382 - val: 0.5153\n",
            "early stopping after epoch 028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jMT80C2-yli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8de38bf9-68d5-437f-d1d7-79cdd4f17657"
      },
      "source": [
        "#Plot the training and validation losses\n",
        "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK8YxbxLG0lW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "89d9e90e-7c63-479f-e620-e3e517cb3be9"
      },
      "source": [
        "#Plot each epoches\n",
        "_ = plt.plot(lr_history[:2*iterations_per_epoch])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfz3IV0uG2C_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8faf59f4-3b8a-4789-b015-c7950b2ffd9e"
      },
      "source": [
        "net.load_state_dict(best_weights)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJplX3Q5G3-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e86d093-88a8-45bc-b851-2807667a83c0"
      },
      "source": [
        "#make prediction and evaluate the model\n",
        "groud_truth, predictions = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
        "        x_batch, y_batch = [b.to(device) for b in batch]\n",
        "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
        "        groud_truth.extend(y_batch.tolist())\n",
        "        predictions.extend(outputs.tolist())\n",
        "\n",
        "groud_truth = np.asarray(groud_truth).ravel()\n",
        "predictions = np.asarray(predictions).ravel()\n",
        "\n",
        "#Find the final loss\n",
        "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
        "print(f'Final RMSE: {final_loss:.4f}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final RMSE: 0.8294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8SwNpA0HCqi"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}